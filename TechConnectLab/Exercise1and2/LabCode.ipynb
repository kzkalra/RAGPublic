{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "\n",
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "\n",
    "config_list_dalle3 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\"model\": [\"dall-e-3\"]},\n",
    ")\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\"model\": [\"gpt-4\", \"gpt-4-Vision\", \"gpt4\", \"gpt-4-32k\"]},\n",
    ")\n",
    "\n",
    "# Assign the configuration to the respective config variables as per Step 1, paste the code below.\n",
    "# <Step 1 code goes here>\n",
    "\n",
    "# Initialize User Proxy Agent\n",
    "# <Step 2 code goes here>\n",
    "\n",
    "\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    name=\"Tour_Planner_Agent\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    # <Step 3 code goes here>\n",
    "    llm_config=llm_config_gpt4,\n",
    "    description=\"Tour Planner Agent to can plan travel in international travels.\",\n",
    ")\n",
    "\n",
    "localtourist_Guide = AssistantAgent(\n",
    "    name=\"Local_Tourist_Guide\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    # <Step 4 code goes here>\n",
    "    llm_config=llm_config_gpt4,\n",
    "    description=\"knowledgeable, personable, and insightful Local Tourist Guide Agent\",\n",
    ")\n",
    "\n",
    "prompt_agent = AssistantAgent(\n",
    "    name=\"Prompt_Agent\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message='''You are a prompt engineer for image generation tasks using the DALL-E model.\n",
    "      Your goal is to generate creative and accurate image prompts for the model based on user input.\n",
    " \n",
    "      **Your Responsibilities:**\n",
    " \n",
    "      1. **Analyze Itinerary:** Carefully read the itinerary and identify their desired image\n",
    "      2. **Understand User Preferences:** Determine the user's preferred style, tone, and overall aesthetic (e.g., realistic, cartoon, abstract, whimsical).\n",
    "      3. **Generate Image Prompts:** Craft one or more detailed image generation prompts based on the itinerary and preferences.\n",
    "          - **Clarity is Key:** Make sure your prompts are clear, specific, and easy for the DALL-E model to interpret.\n",
    "          - **Include Details:** Provide information about subject, setting, action, style, and composition.\n",
    "          - **Use Descriptive Language:**  Choose words and phrases that evoke the desired visual style and imagery.\n",
    " \n",
    "      Please make sure your response only contains prompt sentences, without including any description or introduction of this prompt.\n",
    "      ''',\n",
    "    llm_config=llm_config_gpt4,\n",
    "    description=\"Generates prompts for DallE agent.\"\n",
    ")\n",
    "dalle_agent = ConversableAgent(\n",
    "    name=\"Dalle_Agent\",\n",
    "    default_auto_reply= f\"Image URL generated\",\n",
    "    description=\"Generates images using DallE model based on the input from prompt agent\",\n",
    ")\n",
    " \n",
    "def generate_image(recipient, messages, sender, config):\n",
    "    # Extract the llm_config from the config parameter\n",
    "    llm_config = config.get(\"llm_config\", {})\n",
    "    config_list = llm_config.get(\"config_list\", [])\n",
    "    \n",
    "    # Extract the relevant configuration details\n",
    "    if config_list:\n",
    "        model_config = config_list[0]\n",
    "        api_version = model_config.get(\"api_version\")\n",
    "        api_key = model_config.get(\"api_key\")\n",
    "        azure_endpoint = model_config.get(\"base_url\")\n",
    "    else:\n",
    "        raise ValueError(\"Configuration list is empty or missing required details.\")\n",
    "    \n",
    "    # Initialize the AzureOpenAI client with the provided configuration\n",
    "    client = AzureOpenAI(\n",
    "        api_version=api_version,  \n",
    "        api_key=api_key,  \n",
    "        azure_endpoint=azure_endpoint,\n",
    "    )\n",
    "    print(messages[-1]['content'])\n",
    "    result = client.images.generate(\n",
    "        model=\"dall-e-3\", # the name of your DALL-E 3 deployment\n",
    "        prompt=\"\"\"\n",
    "    Strictly just convert the text to image and make it more visually appealing . It should look like reading the text. Dont not modify the text in any way.\n",
    "        \"\"\"+messages[-1]['content'],\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    json_response = json.loads(result.model_dump_json())\n",
    "\n",
    "    # Set the directory for the stored image\n",
    "    image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "    # If the directory doesn't exist, create it\n",
    "    if not os.path.isdir(image_dir):\n",
    "        os.mkdir(image_dir)\n",
    "\n",
    "    # Initialize the image path (note the filetype should be png)\n",
    "    image_path = os.path.join(image_dir, 'generated_image.png')\n",
    "\n",
    "    # Retrieve the generated image\n",
    "    image_url = json_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "    generated_image = requests.get(image_url).content  # download the image\n",
    "    with open(image_path, \"wb\") as image_file:\n",
    "        image_file.write(generated_image)\n",
    "\n",
    "    # Display the image in the default image viewer\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    return False, {\"content\": messages}\n",
    "\n",
    "dalle_agent.register_reply(\n",
    "        [autogen.Agent, None],\n",
    "        reply_func=generate_image,\n",
    "        config={\"llm_config\": llm_config_dalle3},\n",
    "    )\n",
    "\n",
    "def _reset_agents():\n",
    "    boss.reset()\n",
    "    planner.reset()\n",
    "    localtourist_Guide.reset()\n",
    "    prompt_agent.reset()\n",
    "    dalle_agent.reset()\n",
    "\n",
    "\n",
    "def chat_travel(preferences: dict):\n",
    "    _reset_agents()\n",
    "    preferences_message = (\n",
    "        f\"Create a two-day outing plan for Seattle in February. Include:  {preferences['activities']}\\n- Meal preferences: {preferences['meals']}\\n- Transport: {preferences['transport']}.\"\n",
    "    )\n",
    "    # <Step 5 code goes here>\n",
    "    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config_gpt4)\n",
    "\n",
    "    # Start chatting with the boss as this is the user proxy agent.\n",
    "    result= boss.initiate_chat(\n",
    "        manager,\n",
    "        message=preferences_message,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "preferences = {\n",
    "    \"activities\": \"outdoor attractions, museums, and scenic viewpoints\",\n",
    "    \"meals\": \"vegetarian options with local specialties\",\n",
    "    \"transport\": \"public transit and walking\"\n",
    "}\n",
    "\n",
    "result=chat_travel(preferences)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
